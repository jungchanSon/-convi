// VS Code API ê°€ì ¸ì˜¤ê¸°
import * as vscode from 'vscode';
// Git ìœ í‹¸ í•¨ìˆ˜ë“¤ ê°€ì ¸ì˜¤ê¸° (ì €ì¥ì†Œ ê°ì§€, diff ì¡°íšŒ, ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ê²½ë¡œ)
import { isGitRepo, getStagedDiff, getWorkspacePath } from './gitUtils';
import * as path from 'path';
import * as fs from "fs";
import OpenAI from 'openai';
import { createGitHook } from './createGitHook';


// í”ŒëŸ¬ê·¸ì¸ í™œì„±í™” ì‹œ í˜¸ì¶œ
export function activate(context: vscode.ExtensionContext) {
  console.log('"commit-buddy" í”ŒëŸ¬ê·¸ì¸ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤!');

  // ì„¤ì •ì—ì„œ ëª¨ë¸ ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: llama3.2:latest)
  const config = vscode.workspace.getConfiguration('commitBuddy');
  const {provider, modelName, modelKey} = getLLMConfig();
  
  // ë°±ê·¸ë¼ìš´ë“œì—ì„œ ëª¨ë¸ ë¯¸ë¦¬ ë¡œë“œ (í™œì„±í™” ì‹œ ëª¨ë¸ ì¤€ë¹„)
  if(provider === "Ollama") {
    preloadModel(modelName);
  }

  // [1] Staged Diff ì¶œë ¥ ì»¤ë§¨ë“œ ë“±ë¡
  const diffDisposable = vscode.commands.registerCommand('commit-buddy.showStagedDiff', async () => {
    const workspacePath = getWorkspacePath();
    if (!workspacePath) {
      vscode.window.showErrorMessage('ì›Œí¬ìŠ¤í˜ì´ìŠ¤ê°€ ì—´ë ¤ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.');
      return;
    }

    const isRepo = await isGitRepo(workspacePath);
    if (!isRepo) {
      vscode.window.showErrorMessage('Git ì €ì¥ì†Œê°€ ì•„ë‹™ë‹ˆë‹¤.');
      return;
    }

    const diff = await getStagedDiff(workspacePath);
    if (!diff) {
      vscode.window.showInformationMessage('ìŠ¤í…Œì´ì§€ëœ ë³€ê²½ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.');
    } else {
      console.log('ğŸ“¦ ìŠ¤í…Œì´ì§€ëœ ë³€ê²½ì‚¬í•­ (Diff):', diff);
    }
  });
  context.subscriptions.push(diffDisposable);

  /**
   * Ollamaì— íŠ¹ì • ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
   * @param model í™•ì¸í•  ëª¨ë¸ ì´ë¦„
   * @returns ëª¨ë¸ ì¡´ì¬ ì—¬ë¶€ (true/false)
   */
  async function checkOllamaModel(model: string): Promise<boolean> {
    try {
      const response = await fetch('http://localhost:11434/api/tags');
      const data = await response.json() as { models: { name: string }[] };
      const models = data.models.map((m) => m.name);
      console.log('ì„¤ì¹˜ëœ Ollama ëª¨ë¸ ëª©ë¡:', models);
      return models.includes(model);
    } catch (error) {
      console.error('Ollama ì„œë²„ ì—°ê²° ì˜¤ë¥˜:', error);
      vscode.window.showErrorMessage('Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.');
      return false;
    }
  }

  /**
   * Ollama ëª¨ë¸ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¯¸ë¦¬ ë¡œë“œ
   * @param model ë¡œë“œí•  ëª¨ë¸ ì´ë¦„
   */
  async function preloadModel(model: string): Promise<void> {
    try {
      // ëª¨ë¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
      const modelExists = await checkOllamaModel(model);
      if (!modelExists) {
        console.log(`ëª¨ë¸ '${model}'ì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì•„ ì‚¬ì „ ë¡œë”©ì„ ê±´ë„ˆëœë‹ˆë‹¤.`);
        return;
      }

      // ìƒíƒœ í‘œì‹œì¤„ì— ë¡œë”© ë©”ì‹œì§€ í‘œì‹œ
      const loadingMessage = vscode.window.setStatusBarMessage(`$(sync~spin) Commit Buddy: ${model} ëª¨ë¸ ì¤€ë¹„ ì¤‘...`);
      
      // ë§¤ìš° ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¡œ ëª¨ë¸ ë©”ëª¨ë¦¬ì— ë¡œë“œ
      const startTime = Date.now();
      await fetch('http://localhost:11434/api/generate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: model,
          prompt: 'Hello',
          stream: false
        })
      });

      const loadTime = Date.now() - startTime;
      console.log(`ëª¨ë¸ '${model}' ì‚¬ì „ ë¡œë”© ì™„ë£Œ (${loadTime}ms)`);
      
      // ë¡œë”© ì™„ë£Œ ë©”ì‹œì§€ë¡œ ë³€ê²½
      loadingMessage.dispose();
      vscode.window.setStatusBarMessage(`Commit Buddy: ${model} ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ`, 3000);
    } catch (error) {
      console.error('ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì¤‘ ì˜¤ë¥˜:', error);
      // ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ í”ŒëŸ¬ê·¸ì¸ ì‚¬ìš©ì— ì˜í–¥ì´ ì—†ë„ë¡ ì¡°ìš©íˆ ì‹¤íŒ¨
    }
  }

  // ì»¤ë°‹ ë©”ì‹œì§€ ì¶”ì²œ ì»¤ë§¨ë“œ ë“±ë¡
  const recommendDisposable = vscode.commands.registerCommand('commit-buddy.recommendMessage', async () => {
    const workspacePath = getWorkspacePath();
    if (!workspacePath) {
      vscode.window.showErrorMessage('ì›Œí¬ìŠ¤í˜ì´ìŠ¤ê°€ ì—´ë ¤ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.');
      return;
    }

    const isRepo = await isGitRepo(workspacePath);
    if (!isRepo) {
      vscode.window.showErrorMessage('Git ì €ì¥ì†Œê°€ ì•„ë‹™ë‹ˆë‹¤.');
      return;
    }

    const diff = await getStagedDiff(workspacePath);
    if (!diff) {
      vscode.window.showInformationMessage('ìŠ¤í…Œì´ì§€ëœ ë³€ê²½ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    // ì„¤ì •ì—ì„œ ëª¨ë¸ ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: llama3.2:latest)
    const config = vscode.workspace.getConfiguration('commitBuddy');
    const {provider, modelName, modelKey} = getLLMConfig();

    if(provider === 'Ollama'){
      const modelExists = await checkOllamaModel(modelName);
      if (!modelExists) {
        const installOption = 'ëª¨ë¸ ì„¤ì¹˜';
        const result = await vscode.window.showErrorMessage(
          `${modelName} ëª¨ë¸ì´ Ollamaì— ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.`,
          installOption,
          'ì·¨ì†Œ'
        );
        
        if (result === installOption) {
          // í„°ë¯¸ë„ ì—´ê³  ëª¨ë¸ ì„¤ì¹˜ ëª…ë ¹ì–´ ì‹¤í–‰
          const terminal = vscode.window.createTerminal('Ollama Model Install');
          terminal.sendText(`ollama pull ${modelName}`);
          terminal.show();
        }
        return;
      }
    }
   

    try {
      // ë¡œë”© ë©”ì‹œì§€ í‘œì‹œ
      const statusBarItem = vscode.window.createStatusBarItem(vscode.StatusBarAlignment.Left, 100);
      
      var recommendedMessages;

      statusBarItem.text = "$(sync~spin) ì»¤ë°‹ ë©”ì‹œì§€ ì¶”ì²œ ì¤‘...";
      statusBarItem.show();
      
      if(provider === "OpenAI") {
        recommendedMessages = await fetchGPTRecommendation(diff, modelName, modelKey);
      } else {
        recommendedMessages = await fetchOllamaRecommendation(diff, modelName);
      }
      statusBarItem.dispose();

      // ê° ì¶”ì²œ ë©”ì‹œì§€ë¥¼ ë³„ë„ì˜ QuickPickItemìœ¼ë¡œ ë³€í™˜
      const options: vscode.QuickPickItem[] = [
        ...recommendedMessages.map(msg => ({
          label: msg,
          description: '' // í•„ìš”ì‹œ ì—¬ê¸°ì— ì„¤ëª… ì¶”ê°€ ê°€ëŠ¥
        })),
        // ì§ì ‘ ì…ë ¥ ì˜µì…˜
        {
          label: '$(pencil) ì§ì ‘ ì…ë ¥...',
          description: ''
        }
      ];

      const selected = await vscode.window.showQuickPick(options, {
        placeHolder: 'ì¶”ì²œ ì»¤ë°‹ ë©”ì‹œì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”'
      });

      if (selected) {
        if (selected.label === '$(pencil) ì§ì ‘ ì…ë ¥...') {
          const userInput = await vscode.window.showInputBox({
            placeHolder: 'ì»¤ë°‹ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”'
          });
          
          if (userInput) {
            await commitWithMessage(userInput);
          }
        } else {
          await commitWithMessage(selected.label);
        }
      }
    } catch (error) {
      vscode.window.showErrorMessage(`ì˜¤ë¥˜ ë°œìƒ: ${error instanceof Error ? error.message : String(error)}`);
    }
  });
  context.subscriptions.push(recommendDisposable);

  // Git Hook íŒŒì¼ ìƒì„± ì»¤ë§¨ë“œ ë“±ë¡
  context.subscriptions.push(
    vscode.commands.registerCommand('commit-buddy.createGitHook', createGitHook)
  );

  // í”ŒëŸ¬ê·¸ì¸ ì„¤ì • ë“±ë¡
  context.subscriptions.push(
    vscode.workspace.onDidChangeConfiguration(e => {
      if (e.affectsConfiguration('commitBuddy')) {
        // ì„¤ì •ì´ ë³€ê²½ë˜ë©´ ëª¨ë¸ ë‹¤ì‹œ ë¡œë“œ
        console.log('Commit Buddy ì„¤ì •ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.');
        const newModelName = config.get<string>('modelName') || 'llama3.2:latest';
        preloadModel(newModelName);
      }
    })
  );
}

/**
 * ì»¤ë°‹ ì‹¤í–‰ í•¨ìˆ˜
 * @param message ì»¤ë°‹ ë©”ì‹œì§€
 */
async function commitWithMessage(message: string): Promise<void> {
  try {
    // Git ì»¤ë°‹ ëª…ë ¹ ì‹¤í–‰
    // await vscode.commands.executeCommand('git.commitStagedWithMessage', message);
    const gitExtension = vscode.extensions.getExtension('vscode.git');
    if (!gitExtension) {
      throw new Error('Unable to find the Git extension.');
    }

    const api = gitExtension.exports.getAPI(1);
    if (!api || api.repositories.length === 0) {
      throw new Error('Unable to access the Git repositories.');
    }

    const repository = api.repositories[0];

    repository.inputBox.value = message;
    
    vscode.window.showInformationMessage(`ì»¤ë°‹ ì¶”ì²œ ì™„ë£Œ: ${message}`);
  } catch (error) {
    vscode.window.showErrorMessage(`ì»¤ë°‹ ì¶”ì²œ ì‹¤íŒ¨: ${error instanceof Error ? error.message : String(error)}`);
  }
}

// function readConvirc(): string|null {
//   const workspaceFolders = vscode.workspace.workspaceFolders;
  
//   if(!workspaceFolders || workspaceFolders.length === 0) {
//     return null;
//   }

//   const fsPath = workspaceFolders[0].uri.fsPath;
//   const convircPath = path.join(fsPath, ".convirc");
//   if(!fs.existsSync(convircPath)) {
//     vscode.window.showWarningMessage(`.convircê°€ ì—†ìŠµë‹ˆë‹¤. root ë””ë ‰í† ë¦¬ì— .convircë¥¼ ì¶”ê°€í•˜ë©´, ê·œì¹™ì— ë§ê²Œ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.`);
//     return null;
//   }

//   const content = fs.readFileSync(convircPath, 'utf-8');

//   return content;
// }

/**
 * Ollama LLM API í˜¸ì¶œ í•¨ìˆ˜
 * @param diff Git diff ë¬¸ìì—´
 * @param modelName ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
 * @returns ì¶”ì²œ ì»¤ë°‹ ë©”ì‹œì§€ ë°°ì—´
 */
async function fetchOllamaRecommendation(diff: string, modelName: string): Promise<string[]> {
  // diff ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ë©´ ì§§ê²Œ ì¤„ì´ê¸° (í•„ìš” ì‹œ)
  const truncatedDiff = diff.length > 2000 ? diff.substring(0, 2000) + '...(truncated)' : diff;

  // íƒ€ì„ì•„ì›ƒ ì„¤ì •
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), 20000); // 20ì´ˆ íƒ€ì„ì•„ì›ƒ
  const config = vscode.workspace.getConfiguration('commitBuddy');
  const regex = config.get<string>('regex') || '<type>: <description>';
  const prompt = createPrompt(regex, diff);

  try {
    const response = await fetch('http://localhost:11434/api/generate', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: modelName,
        prompt: prompt,
        stream: false
      }),
      signal: controller.signal
    });

    clearTimeout(timeoutId);
    const data = await response.json() as { response?: string };
    console.log('LLM ì‘ë‹µ:', data);
    // ì‘ë‹µì—ì„œ ì»¤ë°‹ ë©”ì‹œì§€ ì¶”ì¶œ ë¡œì§ ê°œì„ 
    const responseText = data?.response || '';
    let suggestions: string[] = [];
    
    // íŒ¨í„´ 1: ìˆ«ì+ì  í˜•ì‹ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸ ì°¾ê¸°
    // const numberedPattern = /^\s*(\d+)\.\s*([a-z]+(\([a-z-]+\))?:.+)$/gm;
    // let match;
    // const numberedMatches = [];
    
    // while ((match = numberedPattern.exec(responseText)) !== null) {
    //   numberedMatches.push(match[2].trim());
    // }
    // console.log("numberedMatches", numberedMatches);

    // if (numberedMatches.length > 0) {
    //   suggestions = numberedMatches;
    // } else {
      // íŒ¨í„´ 2: ê° ì¤„ì´ <type>: <subject> í˜•ì‹ì¸ì§€ í™•ì¸
    const lines = responseText.split(/\d\.\s+/)
      .map(line => line.trim())
      .filter(line => line.length > 0);

    // const typePattern = /^[a-z]+(\([a-z-]+\))?:.+$/;
    // suggestions = lines.filter(line => typePattern.test(line));
    // }
    lines.splice(0,1);
    suggestions = lines;
    // ì œì•ˆ ë©”ì‹œì§€ê°€ ì—†ê±°ë‚˜ 3ê°œ ë¯¸ë§Œì¸ ê²½ìš°, ê¸°ë³¸ ë©”ì‹œì§€ ì¶”ê°€
    if (suggestions.length === 0) {
      // ê¸°ë³¸ ë©”ì‹œì§€ ì œì•ˆ
      suggestions = [
        'feat: Implement new feature based on changes',
        'fix: Fix issue related to the modified code',
        'chore: Update project dependencies and configuration'
      ];
      vscode.window.showWarningMessage('AIê°€ ì ì ˆí•œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ë©”ì‹œì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤.');
    }
    
    // ìµœëŒ€ 3ê°œì˜ ì œì•ˆìœ¼ë¡œ ì œí•œ
    return suggestions.slice(0, 3);
  } catch (error: unknown) {
    if (error instanceof Error && error.name === 'AbortError') {
      console.error('LLM ìš”ì²­ íƒ€ì„ì•„ì›ƒ');
      return ['ì‘ë‹µ ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë ¤ ìš”ì²­ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.'];
    }
    console.error('LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜:', error);
    throw error;
  } finally {
    clearTimeout(timeoutId);
  }
}

async function fetchGPTRecommendation(diff: string, modelName: string, modelKey: string): Promise<string[]> {
  const client = new OpenAI({apiKey: modelKey});

  // diff ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ë©´ ì§§ê²Œ ì¤„ì´ê¸° (í•„ìš” ì‹œ)
  const truncatedDiff = diff.length > 2000 ? diff.substring(0, 2000) + '...(truncated)' : diff;
  
  // íƒ€ì„ì•„ì›ƒ ì„¤ì •
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), 20000); // 20ì´ˆ íƒ€ì„ì•„ì›ƒ
  const config = vscode.workspace.getConfiguration('commitBuddy');
  const regex = config.get<string>('regex') || '<type>: <description>';
  const prompt = createPrompt(regex, diff);

  try {
    const response = await client.responses.create({
        model: modelName,
        input: prompt,
    });
    
    clearTimeout(timeoutId);
    const data = response;
    console.log('LLM ì‘ë‹µ:', data);

    const responseText = response.output_text;
    let suggestions: string[] = [];
    
    const lines = responseText.split(/\d\.\s+/)
      .map(line => line.trim())
      .filter(line => line.length > 0);

    suggestions = lines;
    // ì œì•ˆ ë©”ì‹œì§€ê°€ ì—†ê±°ë‚˜ 3ê°œ ë¯¸ë§Œì¸ ê²½ìš°, ê¸°ë³¸ ë©”ì‹œì§€ ì¶”ê°€
    if (suggestions.length === 0) {
      // ê¸°ë³¸ ë©”ì‹œì§€ ì œì•ˆ
      suggestions = [
        'feat: Implement new feature based on changes',
        'fix: Fix issue related to the modified code',
        'chore: Update project dependencies and configuration'
      ];
      vscode.window.showWarningMessage('AIê°€ ì ì ˆí•œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ë©”ì‹œì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤.');
    }
    
    // ìµœëŒ€ 3ê°œì˜ ì œì•ˆìœ¼ë¡œ ì œí•œ
    return suggestions.slice(0, 3);
  } catch (error: unknown) {
    if (error instanceof Error && error.name === 'AbortError') {
      console.error('LLM ìš”ì²­ íƒ€ì„ì•„ì›ƒ');
      return ['ì‘ë‹µ ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë ¤ ìš”ì²­ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.'];
    }
    console.error('LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜:', error);
    throw error;
  } finally {
    clearTimeout(timeoutId);
  }
}

type LLMConfig = {
  provider: string,
  modelName: string,
  modelKey: string
}

function getLLMConfig(): LLMConfig {
  const config = vscode.workspace.getConfiguration('commitBuddy');
  const provider = config.get<string>("LLM") || 'Ollama';
  
  var modelName = '';
  var modelKey = '';
  
  if(provider === "OpenAI") {
    modelKey = config.get<string>('openAI.ModelKey') || '';
    if(modelKey.length === 0) {
      vscode.window.showErrorMessage("OpenAI Keyê°’ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.");
    }
    modelName = config.get<string>('openAI.ModelName') || 'gpt-4.1';
  } else{
    modelName = config.get<string>('ollama.ModelName') || 'llama3.2:latest';
  }

  return {provider, modelName, modelKey} ;
}

// í”ŒëŸ¬ê·¸ì¸ ë¹„í™œì„±í™” ì‹œ í˜¸ì¶œ
export function deactivate() {}

function createPrompt(convirc: string, diff: string) {
  return `Please suggest 3 good commit messages based on the Git diff below and follow example format.

          Rules:
            - Write exactly 3 commit messages
            - Each message must be on a new line, prefixed with a number (1., 2., 3.)
            - Use imperative mood (e.g., Add, Fix, Update)
            - Keep each message under 50 characters
            - Use the conventional commit format (feat, fix, docs, style, refactor, test, chore)
            - Write in English
            - follow example format below

          Example regex:
            ${convirc}

          Git diff:
            ${diff}`;
}